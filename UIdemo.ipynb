{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open D:/myworkspace/JupyterNotebook/fatigue_detecting/model/shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 141\u001B[0m\n\u001B[0;32m    139\u001B[0m detector \u001B[38;5;241m=\u001B[39m dlib\u001B[38;5;241m.\u001B[39mget_frontal_face_detector()\n\u001B[0;32m    140\u001B[0m \u001B[38;5;66;03m# 第二步：使用dlib.shape_predictor获得脸部特征位置检测器\u001B[39;00m\n\u001B[1;32m--> 141\u001B[0m predictor \u001B[38;5;241m=\u001B[39m dlib\u001B[38;5;241m.\u001B[39mshape_predictor(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD:/myworkspace/JupyterNotebook/fatigue_detecting/model/shape_predictor_68_face_landmarks.dat\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    143\u001B[0m \u001B[38;5;66;03m# 第三步：分别获取左右眼面部标志的索引\u001B[39;00m\n\u001B[0;32m    144\u001B[0m (lStart, lEnd) \u001B[38;5;241m=\u001B[39m face_utils\u001B[38;5;241m.\u001B[39mFACIAL_LANDMARKS_IDXS[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft_eye\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Unable to open D:/myworkspace/JupyterNotebook/fatigue_detecting/model/shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "opencv视频版\n",
    "\n",
    "\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np # 数据处理的库 numpy\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "\n",
    " \n",
    "# 世界坐标系(UVW)：填写3D参考点，该模型参考http://aifi.isr.uc.pt/Downloads/OpenGL/glAnthropometric3DModel.cpp\n",
    "object_pts = np.float32([[6.825897, 6.760612, 4.402142],  #33左眉左上角\n",
    "                         [1.330353, 7.122144, 6.903745],  #29左眉右角\n",
    "                         [-1.330353, 7.122144, 6.903745], #34右眉左角\n",
    "                         [-6.825897, 6.760612, 4.402142], #38右眉右上角\n",
    "                         [5.311432, 5.485328, 3.987654],  #13左眼左上角\n",
    "                         [1.789930, 5.393625, 4.413414],  #17左眼右上角\n",
    "                         [-1.789930, 5.393625, 4.413414], #25右眼左上角\n",
    "                         [-5.311432, 5.485328, 3.987654], #21右眼右上角\n",
    "                         [2.005628, 1.409845, 6.165652],  #55鼻子左上角\n",
    "                         [-2.005628, 1.409845, 6.165652], #49鼻子右上角\n",
    "                         [2.774015, -2.080775, 5.048531], #43嘴左上角\n",
    "                         [-2.774015, -2.080775, 5.048531],#39嘴右上角\n",
    "                         [0.000000, -3.116408, 6.097667], #45嘴中央下角\n",
    "                         [0.000000, -7.415691, 4.070434]])#6下巴角\n",
    "\n",
    "# 相机坐标系(XYZ)：添加相机内参\n",
    "K = [6.5308391993466671e+002, 0.0, 3.1950000000000000e+002,\n",
    "     0.0, 6.5308391993466671e+002, 2.3950000000000000e+002,\n",
    "     0.0, 0.0, 1.0]# 等价于矩阵[fx, 0, cx; 0, fy, cy; 0, 0, 1]\n",
    "# 图像中心坐标系(uv)：相机畸变参数[k1, k2, p1, p2, k3]\n",
    "D = [7.0834633684407095e-002, 6.9140193737175351e-002, 0.0, 0.0, -1.3073460323689292e+000]\n",
    "\n",
    "# 像素坐标系(xy)：填写凸轮的本征和畸变系数\n",
    "cam_matrix = np.array(K).reshape(3, 3).astype(np.float32)\n",
    "dist_coeffs = np.array(D).reshape(5, 1).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 重新投影3D点的世界坐标轴以验证结果姿势\n",
    "reprojectsrc = np.float32([[10.0, 10.0, 10.0],\n",
    "                           [10.0, 10.0, -10.0],\n",
    "                           [10.0, -10.0, -10.0],\n",
    "                           [10.0, -10.0, 10.0],\n",
    "                           [-10.0, 10.0, 10.0],\n",
    "                           [-10.0, 10.0, -10.0],\n",
    "                           [-10.0, -10.0, -10.0],\n",
    "                           [-10.0, -10.0, 10.0]])\n",
    "# 绘制正方体12轴\n",
    "line_pairs = [[0, 1], [1, 2], [2, 3], [3, 0],\n",
    "              [4, 5], [5, 6], [6, 7], [7, 4],\n",
    "              [0, 4], [1, 5], [2, 6], [3, 7]]\n",
    "\n",
    "def get_head_pose(shape):# 头部姿态估计\n",
    "    # （像素坐标集合）填写2D参考点，注释遵循https://ibug.doc.ic.ac.uk/resources/300-W/\n",
    "    # 17左眉左上角/21左眉右角/22右眉左上角/26右眉右上角/36左眼左上角/39左眼右上角/42右眼左上角/\n",
    "    # 45右眼右上角/31鼻子左上角/35鼻子右上角/48左上角/54嘴右上角/57嘴中央下角/8下巴角\n",
    "    image_pts = np.float32([shape[17], shape[21], shape[22], shape[26], shape[36],\n",
    "                            shape[39], shape[42], shape[45], shape[31], shape[35],\n",
    "                            shape[48], shape[54], shape[57], shape[8]])\n",
    "    # solvePnP计算姿势——求解旋转和平移矩阵：\n",
    "    # rotation_vec表示旋转矩阵，translation_vec表示平移矩阵，cam_matrix与K矩阵对应，dist_coeffs与D矩阵对应。\n",
    "    _, rotation_vec, translation_vec = cv2.solvePnP(object_pts, image_pts, cam_matrix, dist_coeffs)\n",
    "    # projectPoints重新投影误差：原2d点和重投影2d点的距离（输入3d点、相机内参、相机畸变、r、t，输出重投影2d点）\n",
    "    reprojectdst, _ = cv2.projectPoints(reprojectsrc, rotation_vec, translation_vec, cam_matrix,dist_coeffs)\n",
    "    reprojectdst = tuple(map(tuple, reprojectdst.reshape(8, 2)))# 以8行2列显示\n",
    "\n",
    "    # 计算欧拉角calc euler angle\n",
    "    # 参考https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#decomposeprojectionmatrix\n",
    "    rotation_mat, _ = cv2.Rodrigues(rotation_vec)#罗德里格斯公式（将旋转矩阵转换为旋转向量）\n",
    "    pose_mat = cv2.hconcat((rotation_mat, translation_vec))# 水平拼接，vconcat垂直拼接\n",
    "    # decomposeProjectionMatrix将投影矩阵分解为旋转矩阵和相机矩阵\n",
    "    _, _, _, _, _, _, euler_angle = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "    \n",
    "    pitch, yaw, roll = [math.radians(_) for _ in euler_angle]\n",
    " \n",
    " \n",
    "    pitch = math.degrees(math.asin(math.sin(pitch)))\n",
    "    roll = -math.degrees(math.asin(math.sin(roll)))\n",
    "    yaw = math.degrees(math.asin(math.sin(yaw)))\n",
    "    print('pitch:{}, yaw:{}, roll:{}'.format(pitch, yaw, roll))\n",
    "\n",
    "    return reprojectdst, euler_angle# 投影误差，欧拉角\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # 垂直眼标志（X，Y）坐标\n",
    "    A = dist.euclidean(eye[1], eye[5])# 计算两个集合之间的欧式距离\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # 计算水平之间的欧几里得距离\n",
    "    # 水平眼标志（X，Y）坐标\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # 眼睛长宽比的计算\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # 返回眼睛的长宽比\n",
    "    return ear\n",
    " \n",
    "def mouth_aspect_ratio(mouth):# 嘴部\n",
    "    A = np.linalg.norm(mouth[2] - mouth[9])  # 51, 59\n",
    "    B = np.linalg.norm(mouth[4] - mouth[7])  # 53, 57\n",
    "    C = np.linalg.norm(mouth[0] - mouth[6])  # 49, 55\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "# 定义常数\n",
    "# 眼睛长宽比\n",
    "# 闪烁阈值\n",
    "EYE_AR_THRESH = 0.2\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "# 打哈欠长宽比\n",
    "# 闪烁阈值\n",
    "MAR_THRESH = 0.5\n",
    "MOUTH_AR_CONSEC_FRAMES = 3\n",
    "# 瞌睡点头\n",
    "HAR_THRESH = 0.3\n",
    "NOD_AR_CONSEC_FRAMES = 3\n",
    "# 初始化帧计数器和眨眼总数\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "# 初始化帧计数器和打哈欠总数\n",
    "mCOUNTER = 0\n",
    "mTOTAL = 0\n",
    "# 初始化帧计数器和点头总数\n",
    "hCOUNTER = 0\n",
    "hTOTAL = 0\n",
    "\n",
    "# 初始化DLIB的人脸检测器（HOG），然后创建面部标志物预测\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "# 第一步：使用dlib.get_frontal_face_detector() 获得脸部位置检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# 第二步：使用dlib.shape_predictor获得脸部特征位置检测器\n",
    "predictor = dlib.shape_predictor('D:/myworkspace/JupyterNotebook/fatigue_detecting/model/shape_predictor_68_face_landmarks.dat')\n",
    " \n",
    "# 第三步：分别获取左右眼面部标志的索引\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    "# 第四步：打开cv2 本地摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# 从视频流循环帧\n",
    "while True:\n",
    "    # 第五步：进行循环，读取图片，并对图片做维度扩大，并进灰度化\n",
    "    ret, frame = cap.read()\n",
    "    frame = imutils.resize(frame, width=720)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # 第六步：使用detector(gray, 0) 进行脸部位置检测\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # 第七步：循环脸部位置信息，使用predictor(gray, rect)获得脸部特征位置的信息\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        \n",
    "        # 第八步：将脸部特征信息转换为数组array的格式\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # 第九步：提取左眼和右眼坐标\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        # 嘴巴坐标\n",
    "        mouth = shape[mStart:mEnd]        \n",
    "        \n",
    "        # 第十步：构造函数计算左右眼的EAR值，使用平均值作为最终的EAR\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        # 打哈欠\n",
    "        mar = mouth_aspect_ratio(mouth)\n",
    " \n",
    "        # 第十一步：使用cv2.convexHull获得凸包位置，使用drawContours画出轮廓位置进行画图操作\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    " \n",
    "        # 第十二步：进行画图操作，用矩形框标注人脸\n",
    "        left = rect.left()\n",
    "        top = rect.top()\n",
    "        right = rect.right()\n",
    "        bottom = rect.bottom()\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 1)    \n",
    " \n",
    "        '''\n",
    "            分别计算左眼和右眼的评分求平均作为最终的评分，如果小于阈值，则加1，如果连续3次都小于阈值，则表示进行了一次眨眼活动\n",
    "        '''\n",
    "        # 第十三步：循环，满足条件的，眨眼次数+1\n",
    "        if ear < EYE_AR_THRESH:# 眼睛长宽比：0.2\n",
    "            COUNTER += 1\n",
    "           \n",
    "        else:\n",
    "            # 如果连续3次都小于阈值，则表示进行了一次眨眼活动\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                TOTAL += 1\n",
    "            # 重置眼帧计数器\n",
    "            COUNTER = 0\n",
    "            \n",
    "        # 第十四步：进行画图操作，同时使用cv2.putText将眨眼次数进行显示\n",
    "        cv2.putText(frame, \"Faces: {}\".format(len(rects)), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)     \n",
    "        cv2.putText(frame, \"COUNTER: {}\".format(COUNTER), (150, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) \n",
    "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (450, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        \n",
    "        '''\n",
    "            计算张嘴评分，如果小于阈值，则加1，如果连续3次都小于阈值，则表示打了一次哈欠，同一次哈欠大约在3帧\n",
    "        '''\n",
    "        # 同理，判断是否打哈欠    \n",
    "        if mar > MAR_THRESH:# 张嘴阈值0.5\n",
    "            mCOUNTER += 1\n",
    "            cv2.putText(frame, \"Yawning!\", (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # 如果连续3次都小于阈值，则表示打了一次哈欠\n",
    "            if mCOUNTER >= MOUTH_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                mTOTAL += 1\n",
    "            # 重置嘴帧计数器\n",
    "            mCOUNTER = 0\n",
    "        cv2.putText(frame, \"COUNTER: {}\".format(mCOUNTER), (150, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) \n",
    "        cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (300, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Yawning: {}\".format(mTOTAL), (450, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        \"\"\"\n",
    "        瞌睡点头\n",
    "        \"\"\"\n",
    "        # 第十五步：获取头部姿态\n",
    "        reprojectdst, euler_angle = get_head_pose(shape)\n",
    "        \n",
    "        har = euler_angle[0, 0]# 取pitch旋转角度\n",
    "        if har > HAR_THRESH:# 点头阈值0.3\n",
    "            hCOUNTER += 1\n",
    "        else:\n",
    "            # 如果连续3次都小于阈值，则表示瞌睡点头一次\n",
    "            if hCOUNTER >= NOD_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                hTOTAL += 1\n",
    "            # 重置点头帧计数器\n",
    "            hCOUNTER = 0\n",
    "        \n",
    "        # 绘制正方体12轴\n",
    "        for start, end in line_pairs:\n",
    "            cv2.line(frame, reprojectdst[start], reprojectdst[end], (0, 0, 255))\n",
    "        # 显示角度结果\n",
    "        cv2.putText(frame, \"X: \" + \"{:7.2f}\".format(euler_angle[0, 0]), (10, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), thickness=2)# GREEN\n",
    "        cv2.putText(frame, \"Y: \" + \"{:7.2f}\".format(euler_angle[1, 0]), (150, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (255, 0, 0), thickness=2)# BLUE\n",
    "        cv2.putText(frame, \"Z: \" + \"{:7.2f}\".format(euler_angle[2, 0]), (300, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 0, 255), thickness=2)# RED    \n",
    "        cv2.putText(frame, \"Nod: {}\".format(hTOTAL), (450, 90),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "        \n",
    "            \n",
    "        # 第十六步：进行画图操作，68个特征点标识\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "    print('嘴巴实时长宽比:{:.2f} '.format(mar)+\"\\t是否张嘴：\"+str([False,True][mar > MAR_THRESH]))\n",
    "    print('眼睛实时长宽比:{:.2f} '.format(ear)+\"\\t是否眨眼：\"+str([False,True][COUNTER>=1]))\n",
    "    \n",
    "    # 确定疲劳提示:眨眼50次，打哈欠15次，瞌睡点头15次\n",
    "    if TOTAL >= 50 or mTOTAL>=15 or hTOTAL>=15:\n",
    "        cv2.putText(frame, \"SLEEP!!!\", (100, 200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 3)\n",
    "        \n",
    "    # 按q退出\n",
    "    cv2.putText(frame, \"Press 'q': Quit\", (20, 500),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (84, 255, 159), 2)\n",
    "    # 窗口显示 show with opencv\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# 释放摄像头 release camera\n",
    "cap.release()\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wxpython界面初始化加载完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in thread started by <bound method Fatigue_detecting._learning_face of <__main__.Fatigue_detecting object at 0x000002C7AF904E58>>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d02bb4eed2ef>\u001B[0m in \u001B[0;36m_learning_face\u001B[1;34m(self, event)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[0mflag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim_rd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m             \u001B[1;31m# 取灰度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[0mimg_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim_rd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_RGB2GRAY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m             \u001B[1;31m# 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in thread started by <bound method Fatigue_detecting._learning_face of <__main__.Fatigue_detecting object at 0x000002C7AF904E58>>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d02bb4eed2ef>\u001B[0m in \u001B[0;36m_learning_face\u001B[1;34m(self, event)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[0mflag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim_rd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m             \u001B[1;31m# 取灰度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[0mimg_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim_rd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_RGB2GRAY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m             \u001B[1;31m# 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in thread started by <bound method Fatigue_detecting._learning_face of <__main__.Fatigue_detecting object at 0x000002C7AF904E58>>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d02bb4eed2ef>\u001B[0m in \u001B[0;36m_learning_face\u001B[1;34m(self, event)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[0mflag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim_rd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m             \u001B[1;31m# 取灰度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[0mimg_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim_rd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_RGB2GRAY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m             \u001B[1;31m# 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in thread started by <bound method Fatigue_detecting._learning_face of <__main__.Fatigue_detecting object at 0x000002C7AF904E58>>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d02bb4eed2ef>\u001B[0m in \u001B[0;36m_learning_face\u001B[1;34m(self, event)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[0mflag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim_rd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m             \u001B[1;31m# 取灰度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[0mimg_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim_rd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_RGB2GRAY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m             \u001B[1;31m# 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled exception in thread started by <bound method Fatigue_detecting._learning_face of <__main__.Fatigue_detecting object at 0x000002C7AF904E58>>\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d02bb4eed2ef>\u001B[0m in \u001B[0;36m_learning_face\u001B[1;34m(self, event)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[0mflag\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mim_rd\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m             \u001B[1;31m# 取灰度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[0mimg_gray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mim_rd\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_RGB2GRAY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m             \u001B[1;31m# 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测结束，成功退出程序!!!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "UI界面版\n",
    "\n",
    "\"\"\"\n",
    "# -*- coding: utf-8 -*- \n",
    "\n",
    "import dlib                     # 人脸识别的库dlib\n",
    "import numpy as np              # 数据处理的库numpy\n",
    "import cv2                      # 图像处理的库OpenCv\n",
    "import wx                       # 构造显示界面的GUI\n",
    "import wx.xrc\n",
    "import wx.adv\n",
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np # 数据处理的库 numpy\n",
    "import argparse\n",
    "import imutils\n",
    "import datetime,time\n",
    "import math\n",
    "import os\n",
    "\n",
    "###########################################################################\n",
    "## Class Fatigue_detecting\n",
    "###########################################################################\n",
    "\n",
    "COVER = 'D:/myworkspace/JupyterNotebook/fatigue_detecting/images/camera.png'\n",
    "\n",
    "class Fatigue_detecting(wx.Frame):\n",
    "\n",
    "    def __init__( self, parent, title ):\n",
    "        wx.Frame.__init__ ( self, parent, id = wx.ID_ANY, title = title, pos = wx.DefaultPosition, size = wx.Size( 873,535 ), style = wx.DEFAULT_FRAME_STYLE|wx.TAB_TRAVERSAL )\n",
    "                \n",
    "        self.SetSizeHints( wx.DefaultSize, wx.DefaultSize )\n",
    "        self.SetBackgroundColour( wx.SystemSettings.GetColour( wx.SYS_COLOUR_MENU ) )\n",
    "\n",
    "        bSizer1 = wx.BoxSizer( wx.VERTICAL )\n",
    "        bSizer2 = wx.BoxSizer( wx.HORIZONTAL )\n",
    "        bSizer3 = wx.BoxSizer( wx.VERTICAL )\n",
    "\n",
    "        self.m_animCtrl1 = wx.adv.AnimationCtrl( self, wx.ID_ANY, wx.adv.NullAnimation, wx.DefaultPosition, wx.DefaultSize, wx.adv.AC_DEFAULT_STYLE ) \n",
    "        bSizer3.Add( self.m_animCtrl1, 1, wx.ALL|wx.EXPAND, 5 )        \n",
    "        bSizer2.Add( bSizer3, 9, wx.EXPAND, 5 )\n",
    "        bSizer4 = wx.BoxSizer( wx.VERTICAL )\n",
    "        sbSizer1 = wx.StaticBoxSizer( wx.StaticBox( self, wx.ID_ANY, u\"参数设置\" ), wx.VERTICAL )\n",
    "        sbSizer2 = wx.StaticBoxSizer( wx.StaticBox( sbSizer1.GetStaticBox(), wx.ID_ANY, u\"视频源\" ), wx.VERTICAL )\n",
    "        gSizer1 = wx.GridSizer( 0, 2, 0, 8 )\n",
    "        m_choice1Choices = [ u\"摄像头ID_0\", u\"摄像头ID_1\", u\"摄像头ID_2\" ]\n",
    "        self.m_choice1 = wx.Choice( sbSizer2.GetStaticBox(), wx.ID_ANY, wx.DefaultPosition, wx.Size( 90,25 ), m_choice1Choices, 0 )\n",
    "        self.m_choice1.SetSelection( 0 )\n",
    "        gSizer1.Add( self.m_choice1, 0, wx.ALL, 5 )\n",
    "        self.camera_button1 = wx.Button( sbSizer2.GetStaticBox(), wx.ID_ANY, u\"开始检测\", wx.DefaultPosition, wx.Size( 90,25 ), 0 )\n",
    "        gSizer1.Add( self.camera_button1, 0, wx.ALL, 5 )\n",
    "        self.vedio_button2 = wx.Button( sbSizer2.GetStaticBox(), wx.ID_ANY, u\"打开视频文件\", wx.DefaultPosition, wx.Size( 90,25 ), 0 )\n",
    "        gSizer1.Add( self.vedio_button2, 0, wx.ALL, 5 )\n",
    "\n",
    "        self.off_button3 = wx.Button( sbSizer2.GetStaticBox(), wx.ID_ANY, u\"暂停\", wx.DefaultPosition, wx.Size( 90,25 ), 0 )\n",
    "        gSizer1.Add( self.off_button3, 0, wx.ALL, 5 )\n",
    "        sbSizer2.Add( gSizer1, 1, wx.EXPAND, 5 )\n",
    "        sbSizer1.Add( sbSizer2, 2, wx.EXPAND, 5 )\n",
    "        sbSizer3 = wx.StaticBoxSizer( wx.StaticBox( sbSizer1.GetStaticBox(), wx.ID_ANY, u\"疲劳检测\" ), wx.VERTICAL )\n",
    "        bSizer5 = wx.BoxSizer( wx.HORIZONTAL )\n",
    "        self.yawn_checkBox1 = wx.CheckBox( sbSizer3.GetStaticBox(), wx.ID_ANY, u\"打哈欠检测\", wx.Point( -1,-1 ), wx.Size( -1,15 ), 0 )\n",
    "        self.yawn_checkBox1.SetValue(True) \n",
    "        bSizer5.Add( self.yawn_checkBox1, 0, wx.ALL, 5 )\n",
    "        self.blink_checkBox2 = wx.CheckBox( sbSizer3.GetStaticBox(), wx.ID_ANY, u\"闭眼检测\", wx.Point( -1,-1 ), wx.Size( -1,15 ), 0 )\n",
    "        self.blink_checkBox2.SetValue(True) \n",
    "        bSizer5.Add( self.blink_checkBox2, 0, wx.ALL, 5 )\n",
    "        sbSizer3.Add( bSizer5, 1, wx.EXPAND, 5 )\n",
    "        bSizer6 = wx.BoxSizer( wx.HORIZONTAL )\n",
    "        self.nod_checkBox7 = wx.CheckBox( sbSizer3.GetStaticBox(), wx.ID_ANY, u\"点头检测\", wx.Point( -1,-1 ), wx.Size( -1,15 ), 0 )\n",
    "        self.nod_checkBox7.SetValue(True) \n",
    "        bSizer6.Add( self.nod_checkBox7, 0, wx.ALL, 5 )\n",
    "        self.m_staticText1 = wx.StaticText( sbSizer3.GetStaticBox(), wx.ID_ANY, u\"疲劳时间(秒):\", wx.DefaultPosition, wx.Size( -1,15 ), 0 )\n",
    "        self.m_staticText1.Wrap( -1 )\n",
    "        bSizer6.Add( self.m_staticText1, 0, wx.ALL, 5 )\n",
    "        m_listBox2Choices = [ u\"3\", u\"4\", u\"5\", u\"6\", u\"7\", u\"8\" ]\n",
    "        self.m_listBox2 = wx.ListBox( sbSizer3.GetStaticBox(), wx.ID_ANY, wx.DefaultPosition, wx.Size( 50,24 ), m_listBox2Choices, 0 )\n",
    "        bSizer6.Add( self.m_listBox2, 0, 0, 5 )\n",
    "        sbSizer3.Add( bSizer6, 1, wx.EXPAND, 5 )\n",
    "        sbSizer1.Add( sbSizer3, 2, 0, 5 )\n",
    "        sbSizer4 = wx.StaticBoxSizer( wx.StaticBox( sbSizer1.GetStaticBox(), wx.ID_ANY, u\"脱岗检测\" ), wx.VERTICAL )\n",
    "        bSizer8 = wx.BoxSizer( wx.HORIZONTAL )\n",
    "        self.m_checkBox4 = wx.CheckBox( sbSizer4.GetStaticBox(), wx.ID_ANY, u\"脱岗检测\", wx.DefaultPosition, wx.Size( -1,15 ), 0 )\n",
    "        self.m_checkBox4.SetValue(True) \n",
    "        bSizer8.Add( self.m_checkBox4, 0, wx.ALL, 5 )\n",
    "        self.m_staticText2 = wx.StaticText( sbSizer4.GetStaticBox(), wx.ID_ANY, u\"脱岗时间(秒):\", wx.DefaultPosition, wx.Size( -1,15 ), 0 )\n",
    "        self.m_staticText2.Wrap( -1 )\n",
    "        bSizer8.Add( self.m_staticText2, 0, wx.ALL, 5 )\n",
    "        m_listBox21Choices = [ u\"5\", u\"10\", u\"15\", u\"20\", u\"25\", u\"30\" ]\n",
    "        self.m_listBox21 = wx.ListBox( sbSizer4.GetStaticBox(), wx.ID_ANY, wx.DefaultPosition, wx.Size( 50,24 ), m_listBox21Choices, 0 )\n",
    "        bSizer8.Add( self.m_listBox21, 0, 0, 5 )\n",
    "        sbSizer4.Add( bSizer8, 1, 0, 5 )\n",
    "        sbSizer1.Add( sbSizer4, 1, 0, 5 )\n",
    "        sbSizer5 = wx.StaticBoxSizer( wx.StaticBox( sbSizer1.GetStaticBox(), wx.ID_ANY, u\"分析区域\" ), wx.VERTICAL )\n",
    "        bSizer9 = wx.BoxSizer( wx.HORIZONTAL )\n",
    "        self.m_staticText3 = wx.StaticText( sbSizer5.GetStaticBox(), wx.ID_ANY, u\"检测区域：   \", wx.DefaultPosition, wx.DefaultSize, 0 )\n",
    "        self.m_staticText3.Wrap( -1 )\n",
    "        bSizer9.Add( self.m_staticText3, 0, wx.ALL, 5 )\n",
    "        m_choice2Choices = [ u\"全视频检测\", u\"部分区域选取\" ]\n",
    "        self.m_choice2 = wx.Choice( sbSizer5.GetStaticBox(), wx.ID_ANY, wx.DefaultPosition, wx.DefaultSize, m_choice2Choices, 0 )\n",
    "        self.m_choice2.SetSelection( 0 )\n",
    "        bSizer9.Add( self.m_choice2, 0, wx.ALL, 5 )\n",
    "        sbSizer5.Add( bSizer9, 1, wx.EXPAND, 5 )\n",
    "        sbSizer1.Add( sbSizer5, 1, 0, 5 )\n",
    "        sbSizer6 = wx.StaticBoxSizer( wx.StaticBox( sbSizer1.GetStaticBox(), wx.ID_ANY, u\"状态输出\" ), wx.VERTICAL )\n",
    "        self.m_textCtrl3 = wx.TextCtrl( sbSizer6.GetStaticBox(), wx.ID_ANY, wx.EmptyString, wx.DefaultPosition, wx.DefaultSize, wx.TE_MULTILINE|wx.TE_READONLY )\n",
    "        sbSizer6.Add( self.m_textCtrl3, 1, wx.ALL|wx.EXPAND, 5 )\n",
    "        sbSizer1.Add( sbSizer6, 5, wx.EXPAND, 5 )\n",
    "        bSizer4.Add( sbSizer1, 1, wx.EXPAND, 5 )\n",
    "        bSizer2.Add( bSizer4, 3, wx.EXPAND, 5 )\n",
    "        bSizer1.Add( bSizer2, 1, wx.EXPAND, 5 )\n",
    "\n",
    "        self.SetSizer( bSizer1 )  \n",
    "        self.Layout()\n",
    "        self.Centre( wx.BOTH )\n",
    "        \n",
    "        # Connect Events\n",
    "        self.m_choice1.Bind( wx.EVT_CHOICE, self.cameraid_choice )#绑定事件\n",
    "        self.camera_button1.Bind( wx.EVT_BUTTON, self.camera_on )#开\n",
    "        self.vedio_button2.Bind( wx.EVT_BUTTON, self.vedio_on )\n",
    "        self.off_button3.Bind( wx.EVT_BUTTON, self.off )#关\n",
    "\n",
    "        self.m_listBox2.Bind( wx.EVT_LISTBOX, self.AR_CONSEC_FRAMES )# 闪烁阈值设置\n",
    "        self.m_listBox21.Bind( wx.EVT_LISTBOX, self.OUT_AR_CONSEC_FRAMES )# 脱岗时间设置\n",
    "        \n",
    "        # 封面图片\n",
    "        self.image_cover = wx.Image(COVER, wx.BITMAP_TYPE_ANY)\n",
    "        # 显示图片在m_animCtrl1上\n",
    "        self.bmp = wx.StaticBitmap(self.m_animCtrl1, -1, wx.Bitmap(self.image_cover))\n",
    "\n",
    "        # 设置窗口标题的图标\n",
    "        self.icon = wx.Icon('./images/123.ico', wx.BITMAP_TYPE_ICO)\n",
    "        self.SetIcon(self.icon)\n",
    "        # 系统事件\n",
    "        self.Bind(wx.EVT_CLOSE, self.OnClose)\n",
    "        \n",
    "        print(\"wxpython界面初始化加载完成！\")\n",
    "        \n",
    "        \"\"\"参数\"\"\"\n",
    "        # 默认为摄像头0\n",
    "        self.VIDEO_STREAM = 0\n",
    "        self.CAMERA_STYLE = False # False未打开摄像头，True摄像头已打开\n",
    "        # 闪烁阈值（秒）\n",
    "        self.AR_CONSEC_FRAMES_check = 3\n",
    "        self.OUT_AR_CONSEC_FRAMES_check = 5\n",
    "        # 眼睛长宽比\n",
    "        self.EYE_AR_THRESH = 0.2\n",
    "        self.EYE_AR_CONSEC_FRAMES = self.AR_CONSEC_FRAMES_check\n",
    "        # 打哈欠长宽比\n",
    "        self.MAR_THRESH = 0.5\n",
    "        self.MOUTH_AR_CONSEC_FRAMES = self.AR_CONSEC_FRAMES_check\n",
    "        # 瞌睡点头\n",
    "        self.HAR_THRESH = 0.3\n",
    "        self.NOD_AR_CONSEC_FRAMES = self.AR_CONSEC_FRAMES_check\n",
    "        \n",
    "        \"\"\"计数\"\"\"\n",
    "        # 初始化帧计数器和眨眼总数\n",
    "        self.COUNTER = 0\n",
    "        self.TOTAL = 0\n",
    "        # 初始化帧计数器和打哈欠总数\n",
    "        self.mCOUNTER = 0\n",
    "        self.mTOTAL = 0\n",
    "        # 初始化帧计数器和点头总数\n",
    "        self.hCOUNTER = 0\n",
    "        self.hTOTAL = 0\n",
    "        # 离职时间长度\n",
    "        self.oCOUNTER = 0\n",
    "\n",
    "        \"\"\"姿态\"\"\"\n",
    "        # 世界坐标系(UVW)：填写3D参考点，该模型参考http://aifi.isr.uc.pt/Downloads/OpenGL/glAnthropometric3DModel.cpp\n",
    "        self.object_pts = np.float32([[6.825897, 6.760612, 4.402142],  #33左眉左上角\n",
    "                                 [1.330353, 7.122144, 6.903745],  #29左眉右角\n",
    "                                 [-1.330353, 7.122144, 6.903745], #34右眉左角\n",
    "                                 [-6.825897, 6.760612, 4.402142], #38右眉右上角\n",
    "                                 [5.311432, 5.485328, 3.987654],  #13左眼左上角\n",
    "                                 [1.789930, 5.393625, 4.413414],  #17左眼右上角\n",
    "                                 [-1.789930, 5.393625, 4.413414], #25右眼左上角\n",
    "                                 [-5.311432, 5.485328, 3.987654], #21右眼右上角\n",
    "                                 [2.005628, 1.409845, 6.165652],  #55鼻子左上角\n",
    "                                 [-2.005628, 1.409845, 6.165652], #49鼻子右上角\n",
    "                                 [2.774015, -2.080775, 5.048531], #43嘴左上角\n",
    "                                 [-2.774015, -2.080775, 5.048531],#39嘴右上角\n",
    "                                 [0.000000, -3.116408, 6.097667], #45嘴中央下角\n",
    "                                 [0.000000, -7.415691, 4.070434]])#6下巴角\n",
    "\n",
    "        # 相机坐标系(XYZ)：添加相机内参\n",
    "        self.K = [6.5308391993466671e+002, 0.0, 3.1950000000000000e+002,\n",
    "                 0.0, 6.5308391993466671e+002, 2.3950000000000000e+002,\n",
    "                 0.0, 0.0, 1.0]# 等价于矩阵[fx, 0, cx; 0, fy, cy; 0, 0, 1]\n",
    "        # 图像中心坐标系(uv)：相机畸变参数[k1, k2, p1, p2, k3]\n",
    "        self.D = [7.0834633684407095e-002, 6.9140193737175351e-002, 0.0, 0.0, -1.3073460323689292e+000]\n",
    "\n",
    "        # 像素坐标系(xy)：填写凸轮的本征和畸变系数\n",
    "        self.cam_matrix = np.array(self.K).reshape(3, 3).astype(np.float32)\n",
    "        self.dist_coeffs = np.array(self.D).reshape(5, 1).astype(np.float32)\n",
    "\n",
    "        # 重新投影3D点的世界坐标轴以验证结果姿势\n",
    "        self.reprojectsrc = np.float32([[10.0, 10.0, 10.0],\n",
    "                                       [10.0, 10.0, -10.0],\n",
    "                                       [10.0, -10.0, -10.0],\n",
    "                                       [10.0, -10.0, 10.0],\n",
    "                                       [-10.0, 10.0, 10.0],\n",
    "                                       [-10.0, 10.0, -10.0],\n",
    "                                       [-10.0, -10.0, -10.0],\n",
    "                                       [-10.0, -10.0, 10.0]])\n",
    "        # 绘制正方体12轴\n",
    "        self.line_pairs = [[0, 1], [1, 2], [2, 3], [3, 0],\n",
    "                          [4, 5], [5, 6], [6, 7], [7, 4],\n",
    "                          [0, 4], [1, 5], [2, 6], [3, 7]]\n",
    "        \n",
    "\n",
    "    def __del__( self ):\n",
    "        pass\n",
    "\n",
    "    def get_head_pose(self,shape):# 头部姿态估计\n",
    "        # （像素坐标集合）填写2D参考点，注释遵循https://ibug.doc.ic.ac.uk/resources/300-W/\n",
    "        # 17左眉左上角/21左眉右角/22右眉左上角/26右眉右上角/36左眼左上角/39左眼右上角/42右眼左上角/\n",
    "        # 45右眼右上角/31鼻子左上角/35鼻子右上角/48左上角/54嘴右上角/57嘴中央下角/8下巴角\n",
    "        image_pts = np.float32([shape[17], shape[21], shape[22], shape[26], shape[36],\n",
    "                                shape[39], shape[42], shape[45], shape[31], shape[35],\n",
    "                                shape[48], shape[54], shape[57], shape[8]])\n",
    "        # solvePnP计算姿势——求解旋转和平移矩阵：\n",
    "        # rotation_vec表示旋转矩阵，translation_vec表示平移矩阵，cam_matrix与K矩阵对应，dist_coeffs与D矩阵对应。\n",
    "        _, rotation_vec, translation_vec = cv2.solvePnP(self.object_pts, image_pts, self.cam_matrix, self.dist_coeffs)\n",
    "        # projectPoints重新投影误差：原2d点和重投影2d点的距离（输入3d点、相机内参、相机畸变、r、t，输出重投影2d点）\n",
    "        reprojectdst, _ = cv2.projectPoints(self.reprojectsrc, rotation_vec, translation_vec, self.cam_matrix,self.dist_coeffs)\n",
    "        reprojectdst = tuple(map(tuple, reprojectdst.reshape(8, 2)))# 以8行2列显示\n",
    "\n",
    "        # 计算欧拉角calc euler angle\n",
    "        # 参考https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#decomposeprojectionmatrix\n",
    "        rotation_mat, _ = cv2.Rodrigues(rotation_vec)#罗德里格斯公式（将旋转矩阵转换为旋转向量）\n",
    "        pose_mat = cv2.hconcat((rotation_mat, translation_vec))# 水平拼接，vconcat垂直拼接\n",
    "        # decomposeProjectionMatrix将投影矩阵分解为旋转矩阵和相机矩阵\n",
    "        _, _, _, _, _, _, euler_angle = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "\n",
    "        pitch, yaw, roll = [math.radians(_) for _ in euler_angle]\n",
    "\n",
    "        pitch = math.degrees(math.asin(math.sin(pitch)))\n",
    "        roll = -math.degrees(math.asin(math.sin(roll)))\n",
    "        yaw = math.degrees(math.asin(math.sin(yaw)))\n",
    "        #print('pitch:{}, yaw:{}, roll:{}'.format(pitch, yaw, roll))\n",
    "\n",
    "        return reprojectdst, euler_angle# 投影误差，欧拉角\n",
    "    \n",
    "    def eye_aspect_ratio(self,eye):\n",
    "        # 垂直眼标志（X，Y）坐标\n",
    "        A = dist.euclidean(eye[1], eye[5])# 计算两个集合之间的欧式距离\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        # 计算水平之间的欧几里得距离\n",
    "        # 水平眼标志（X，Y）坐标\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        # 眼睛长宽比的计算\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        # 返回眼睛的长宽比\n",
    "        return ear\n",
    "\n",
    "    def mouth_aspect_ratio(self,mouth):# 嘴部\n",
    "        A = np.linalg.norm(mouth[2] - mouth[9])  # 51, 59\n",
    "        B = np.linalg.norm(mouth[4] - mouth[7])  # 53, 57\n",
    "        C = np.linalg.norm(mouth[0] - mouth[6])  # 49, 55\n",
    "        mar = (A + B) / (2.0 * C)\n",
    "        return mar\n",
    "\n",
    "\n",
    "    def _learning_face(self,event):\n",
    "        \"\"\"dlib的初始化调用\"\"\"\n",
    "        # 使用人脸检测器get_frontal_face_detector\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        # dlib的68点模型，使用作者训练好的特征预测器\n",
    "        self.predictor = dlib.shape_predictor(\"D:/myworkspace/JupyterNotebook/fatigue_detecting/model/shape_predictor_68_face_landmarks.dat\")\n",
    "        self.m_textCtrl3.AppendText(u\"加载模型成功!!!\\n\")\n",
    "        # 分别获取左右眼面部标志的索引\n",
    "        (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "        (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "        (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "        \n",
    "        #建cv2摄像头对象，这里使用电脑自带摄像头，如果接了外部摄像头，则自动切换到外部摄像头\n",
    "        self.cap = cv2.VideoCapture(self.VIDEO_STREAM)\n",
    "        \n",
    "        if self.cap.isOpened()==True:#  返回true/false 检查初始化是否成功\n",
    "            self.CAMERA_STYLE = True\n",
    "            self.m_textCtrl3.AppendText(u\"打开摄像头成功!!!\\n\")\n",
    "        else:\n",
    "            self.m_textCtrl3.AppendText(u\"摄像头打开失败!!!\\n\")\n",
    "            #显示封面图\n",
    "            self.bmp.SetBitmap(wx.Bitmap(self.image_cover))\n",
    "        # 成功打开视频，循环读取视频流\n",
    "        while(self.cap.isOpened()):\n",
    "            # cap.read()\n",
    "            # 返回两个值：\n",
    "            #    一个布尔值true/false，用来判断读取视频是否成功/是否到视频末尾\n",
    "            #    图像对象，图像的三维矩阵\n",
    "            flag, im_rd = self.cap.read()\n",
    "            # 取灰度\n",
    "            img_gray = cv2.cvtColor(im_rd, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # 使用人脸检测器检测每一帧图像中的人脸。并返回人脸数faces\n",
    "            faces = self.detector(img_gray, 0)\n",
    "            # 如果检测到人脸\n",
    "            if(len(faces)!=0):\n",
    "                # enumerate方法同时返回数据对象的索引和数据，k为索引，d为faces中的对象\n",
    "                for k, d in enumerate(faces):\n",
    "                    # 用红色矩形框出人脸\n",
    "                    cv2.rectangle(im_rd, (d.left(), d.top()), (d.right(), d.bottom()), (0, 0, 255),1)\n",
    "                    # 使用预测器得到68点数据的坐标\n",
    "                    shape = self.predictor(im_rd, d)\n",
    "                    # 圆圈显示每个特征点\n",
    "                    for i in range(68):\n",
    "                        cv2.circle(im_rd, (shape.part(i).x, shape.part(i).y), 2, (0, 255, 0), -1, 8)\n",
    "                    # 将脸部特征信息转换为数组array的格式\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \"\"\"\n",
    "                    打哈欠\n",
    "                    \"\"\"\n",
    "                    if self.yawn_checkBox1.GetValue()== True:\n",
    "                        # 嘴巴坐标\n",
    "                        mouth = shape[mStart:mEnd]        \n",
    "                        # 打哈欠\n",
    "                        mar = self.mouth_aspect_ratio(mouth)\n",
    "                        # 使用cv2.convexHull获得凸包位置，使用drawContours画出轮廓位置进行画图操作\n",
    "                        mouthHull = cv2.convexHull(mouth)\n",
    "                        cv2.drawContours(im_rd, [mouthHull], -1, (0, 255, 0), 1)\n",
    "                        # 同理，判断是否打哈欠    \n",
    "                        if mar > self.MAR_THRESH:# 张嘴阈值0.5\n",
    "                            self.mCOUNTER += 1\n",
    "                        else:\n",
    "                            # 如果连续3次都小于阈值，则表示打了一次哈欠\n",
    "                            if self.mCOUNTER >= self.MOUTH_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                                self.mTOTAL += 1\n",
    "                                #显示\n",
    "                                cv2.putText(im_rd, \"Yawning!\", (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                                self.m_textCtrl3.AppendText(time.strftime('%Y-%m-%d %H:%M ', time.localtime())+u\"打哈欠\\n\")\n",
    "                            # 重置嘴帧计数器\n",
    "                            self.mCOUNTER = 0\n",
    "                        cv2.putText(im_rd, \"COUNTER: {}\".format(self.mCOUNTER), (150, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) \n",
    "                        cv2.putText(im_rd, \"MAR: {:.2f}\".format(mar), (300, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        cv2.putText(im_rd, \"Yawning: {}\".format(self.mTOTAL), (450, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "                    else:\n",
    "                        pass\n",
    "                    \"\"\"\n",
    "                    眨眼\n",
    "                    \"\"\"\n",
    "                    if self.blink_checkBox2.GetValue()== True:\n",
    "                        # 提取左眼和右眼坐标\n",
    "                        leftEye = shape[lStart:lEnd]\n",
    "                        rightEye = shape[rStart:rEnd]\n",
    "                        # 构造函数计算左右眼的EAR值，使用平均值作为最终的EAR\n",
    "                        leftEAR = self.eye_aspect_ratio(leftEye)\n",
    "                        rightEAR = self.eye_aspect_ratio(rightEye)\n",
    "                        ear = (leftEAR + rightEAR) / 2.0\n",
    "                        leftEyeHull = cv2.convexHull(leftEye)\n",
    "                        rightEyeHull = cv2.convexHull(rightEye)\n",
    "                        # 使用cv2.convexHull获得凸包位置，使用drawContours画出轮廓位置进行画图操作\n",
    "                        cv2.drawContours(im_rd, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "                        cv2.drawContours(im_rd, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "                        # 循环，满足条件的，眨眼次数+1\n",
    "                        if ear < self.EYE_AR_THRESH:# 眼睛长宽比：0.2\n",
    "                            self.COUNTER += 1\n",
    "\n",
    "                        else:\n",
    "                            # 如果连续3次都小于阈值，则表示进行了一次眨眼活动\n",
    "                            if self.COUNTER >= self.EYE_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                                self.TOTAL += 1\n",
    "                                self.m_textCtrl3.AppendText(time.strftime('%Y-%m-%d %H:%M ', time.localtime())+u\"眨眼\\n\")\n",
    "                            # 重置眼帧计数器\n",
    "                            self.COUNTER = 0\n",
    "                        # 第十四步：进行画图操作，同时使用cv2.putText将眨眼次数进行显示\n",
    "                        cv2.putText(im_rd, \"Faces: {}\".format(len(faces)), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)     \n",
    "                        cv2.putText(im_rd, \"COUNTER: {}\".format(self.COUNTER), (150, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) \n",
    "                        cv2.putText(im_rd, \"EAR: {:.2f}\".format(ear), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        cv2.putText(im_rd, \"Blinks: {}\".format(self.TOTAL), (450, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "                    else:\n",
    "                        pass\n",
    "                    \"\"\"\n",
    "                    瞌睡点头\n",
    "                    \"\"\"\n",
    "                    if self.nod_checkBox7.GetValue()== True:\n",
    "                        # 获取头部姿态\n",
    "                        reprojectdst, euler_angle = self.get_head_pose(shape) \n",
    "                        har = euler_angle[0, 0]# 取pitch旋转角度\n",
    "                        if har > self.HAR_THRESH:# 点头阈值0.3\n",
    "                            self.hCOUNTER += 1\n",
    "                        else:\n",
    "                            # 如果连续3次都小于阈值，则表示瞌睡点头一次\n",
    "                            if self.hCOUNTER >= self.NOD_AR_CONSEC_FRAMES:# 阈值：3\n",
    "                                self.hTOTAL += 1\n",
    "                                self.m_textCtrl3.AppendText(time.strftime('%Y-%m-%d %H:%M ', time.localtime())+u\"瞌睡点头\\n\")\n",
    "                            # 重置点头帧计数器\n",
    "                            self.hCOUNTER = 0\n",
    "                        # 绘制正方体12轴(视频流尺寸过大时，reprojectdst会超出int范围，建议压缩检测视频尺寸)\n",
    "                        for start, end in self.line_pairs:\n",
    "                            cv2.line(im_rd, reprojectdst[start], reprojectdst[end], (0, 0, 255))\n",
    "                        # 显示角度结果\n",
    "                        cv2.putText(im_rd, \"X: \" + \"{:7.2f}\".format(euler_angle[0, 0]), (10, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), thickness=2)# GREEN\n",
    "                        cv2.putText(im_rd, \"Y: \" + \"{:7.2f}\".format(euler_angle[1, 0]), (150, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (255, 0, 0), thickness=2)# BLUE\n",
    "                        cv2.putText(im_rd, \"Z: \" + \"{:7.2f}\".format(euler_angle[2, 0]), (300, 90), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 0, 255), thickness=2)# RED    \n",
    "                        cv2.putText(im_rd, \"Nod: {}\".format(self.hTOTAL), (450, 90),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                #print('嘴巴实时长宽比:{:.2f} '.format(mar)+\"\\t是否张嘴：\"+str([False,True][mar > self.MAR_THRESH]))\n",
    "                #print('眼睛实时长宽比:{:.2f} '.format(ear)+\"\\t是否眨眼：\"+str([False,True][self.COUNTER>=1]))\n",
    "            else:\n",
    "                # 没有检测到人脸\n",
    "                self.oCOUNTER+=1\n",
    "                cv2.putText(im_rd, \"No Face\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),3, cv2.LINE_AA)\n",
    "                if self.oCOUNTER >= self.OUT_AR_CONSEC_FRAMES_check:\n",
    "                    self.m_textCtrl3.AppendText(time.strftime('%Y-%m-%d %H:%M ', time.localtime())+u\"员工脱岗!!!\\n\")\n",
    "                    self.oCOUNTER = 0\n",
    "                \n",
    "            # 确定疲劳提示:眨眼50次，打哈欠15次，瞌睡点头30次\n",
    "            if self.TOTAL >= 50 or self.mTOTAL>=15 or self.hTOTAL>=30:\n",
    "                cv2.putText(im_rd, \"SLEEP!!!\", (100, 200),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 3)\n",
    "                #self.m_textCtrl3.AppendText(u\"疲劳\")\n",
    "                \n",
    "            # opencv中imread的图片内部是BGR排序，wxPython的StaticBitmap需要的图片是RGB排序，不转换会出现颜色变换\n",
    "            height,width = im_rd.shape[:2]\n",
    "            image1 = cv2.cvtColor(im_rd, cv2.COLOR_BGR2RGB)\n",
    "            pic = wx.Bitmap.FromBuffer(width,height,image1)\n",
    "            # 显示图片在panel上：\n",
    "            self.bmp.SetBitmap(pic)\n",
    "\n",
    "        # 释放摄像头\n",
    "        self.cap.release()\n",
    "\n",
    "    def camera_on(self,event):\n",
    "        \"\"\"使用多线程，子线程运行后台的程序，主线程更新前台的UI，这样不会互相影响\"\"\"\n",
    "        import _thread\n",
    "        # 创建子线程，按钮调用这个方法，\n",
    "        _thread.start_new_thread(self._learning_face, (event,))\n",
    "    \n",
    "    def cameraid_choice( self, event ):\n",
    "        # 摄像头编号\n",
    "        cameraid = int(event.GetString()[-1])# 截取最后一个字符\n",
    "        if cameraid == 0:\n",
    "            self.m_textCtrl3.AppendText(u\"准备打开本地摄像头!!!\\n\")\n",
    "        if cameraid == 1 or cameraid == 2:\n",
    "            self.m_textCtrl3.AppendText(u\"准备打开外置摄像头!!!\\n\")\n",
    "        self.VIDEO_STREAM = cameraid\n",
    "        \n",
    "    def vedio_on( self, event ):  \n",
    "        if self.CAMERA_STYLE == True :# 释放摄像头资源\n",
    "            # 弹出关闭摄像头提示窗口\n",
    "            dlg = wx.MessageDialog(None, u'确定要关闭摄像头？', u'操作提示', wx.YES_NO | wx.ICON_QUESTION)\n",
    "            if(dlg.ShowModal() == wx.ID_YES):\n",
    "                self.cap.release()#释放摄像头\n",
    "                self.bmp.SetBitmap(wx.Bitmap(self.image_cover))#封面\n",
    "                dlg.Destroy()#取消弹窗\n",
    "        # 选择文件夹对话框窗口\n",
    "        dialog = wx.FileDialog(self,u\"选择视频检测\",os.getcwd(),'',wildcard=\"(*.mp4)|*.mp4\",style=wx.FD_OPEN | wx.FD_CHANGE_DIR)\n",
    "        if dialog.ShowModal() == wx.ID_OK:\n",
    "            #如果确定了选择的文件夹，将文件夹路径写到m_textCtrl3控件\n",
    "            self.m_textCtrl3.SetValue(u\"文件路径:\"+dialog.GetPath()+\"\\n\")\n",
    "            self.VIDEO_STREAM = str(dialog.GetPath())# 更新全局变量路径\n",
    "            dialog.Destroy\n",
    "            \"\"\"使用多线程，子线程运行后台的程序，主线程更新前台的UI，这样不会互相影响\"\"\"\n",
    "            import _thread\n",
    "            # 创建子线程，按钮调用这个方法，\n",
    "            _thread.start_new_thread(self._learning_face, (event,))\n",
    "    \n",
    "    def AR_CONSEC_FRAMES( self, event ):\n",
    "        self.m_textCtrl3.AppendText(u\"设置疲劳间隔为:\\t\"+event.GetString()+\"秒\\n\")\n",
    "        self.AR_CONSEC_FRAMES_check = int(event.GetString())\n",
    "        \n",
    "    def OUT_AR_CONSEC_FRAMES( self, event ):\n",
    "        self.m_textCtrl3.AppendText(u\"设置脱岗间隔为:\\t\"+event.GetString()+\"秒\\n\")\n",
    "        self.OUT_AR_CONSEC_FRAMES_check = int(event.GetString())\n",
    "\n",
    "    def off(self,event):\n",
    "        \"\"\"关闭摄像头，显示封面页\"\"\"\n",
    "        self.cap.release()\n",
    "        self.bmp.SetBitmap(wx.Bitmap(self.image_cover))\n",
    "        \n",
    "    def OnClose(self, evt):\n",
    "        \"\"\"关闭窗口事件函数\"\"\"\n",
    "        dlg = wx.MessageDialog(None, u'确定要关闭本窗口？', u'操作提示', wx.YES_NO | wx.ICON_QUESTION)\n",
    "        if(dlg.ShowModal() == wx.ID_YES):\n",
    "            self.Destroy()\n",
    "        print(\"检测结束，成功退出程序!!!\")\n",
    "\n",
    "            \n",
    "class main_app(wx.App):\n",
    "    \"\"\"\n",
    "     在OnInit() 里边申请Frame类，这样能保证一定是在app后调用，\n",
    "     这个函数是app执行完自己的__init__函数后就会执行\n",
    "    \"\"\"\n",
    "    # OnInit 方法在主事件循环开始前被wxPython系统调用，是wxpython独有的\n",
    "    def OnInit(self):\n",
    "        self.frame = Fatigue_detecting(parent=None,title=\"Fatigue Demo\")\n",
    "        self.frame.Show(True)\n",
    "        return True   \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app = main_app()\n",
    "    app.MainLoop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
